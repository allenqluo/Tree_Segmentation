{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyproj import Proj\n",
    "import TEAK_class_declarations\n",
    "import math\n",
    "import importlib\n",
    "import pickle\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "objects_path = \"/data/shared/src/STV/NEON_TEAK/allen/object_data\"\n",
    "output_path = '/data/shared/src/STV/NEON_TEAK/allen/figs/model_output/'\n",
    "plot_LAI_path = '/data/shared/src/STV/NEON_TEAK/allen/data/NEON_struct-plant/matching_shapefiles_tiffs.csv'\n",
    "# plot_LAI_path = \"/data/shared/src/STV/NEON_TEAK/allen/figs/model_output/TEAK_sites_LAI_Average_only.csv\"\n",
    "orig_gort_path = '/data/shared/src/STV/NEON_TEAK/allen/Gort/Gort.out/2024_11_13'\n",
    "# orig_gort_path = '/data/shared/src/STV/NEON_TEAK/allen/Gort/Gort.out/2024_11_11_small_footprint'\n",
    "\n",
    "plot_LAI_df = pd.read_csv(plot_LAI_path)\n",
    "\n",
    "section_range = 0.1  # specifies section size.  (section is per 0.1 meters)\n",
    "\n",
    "def load_objects_from_file(filename, path=\"\"):\n",
    "    # Adjust the filename to include the subfolder\n",
    "    if path:\n",
    "        filename = os.path.join(path, filename)\n",
    "        \n",
    "    # Load the objects from file\n",
    "    with open(filename, 'rb') as f:\n",
    "        objects_list = pickle.load(f)\n",
    "    \n",
    "    return objects_list\n",
    "\n",
    "def get_date_subfolder():\n",
    "    current_date = datetime.now()\n",
    "    return current_date.strftime('%Y_%m_%d')\n",
    "\n",
    "date_subfolder = get_date_subfolder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "teak_tree_objects_100 = load_objects_from_file(\"tree_objects_100.pkl\", objects_path)\n",
    "teak_tree_objects_400 = load_objects_from_file(\"tree_objects_400.pkl\", objects_path)\n",
    "teak_plot_objects_100 = load_objects_from_file(\"plot_objects_100.pkl\", objects_path)\n",
    "teak_plot_objects_400 = load_objects_from_file(\"plot_objects_400.pkl\", objects_path)\n",
    "\n",
    "pgap_list = load_objects_from_file(\"TEAK_pgap_list.pkl\", objects_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37. 36. 35. 34. 33. 32. 31. 30. 29. 28. 27. 26. 25. 24. 23. 22. 21. 20.\n",
      " 19. 18. 17. 16. 15. 14. 13. 12. 11. 10.  9.  8.  7.  6.  5.  4.  3.  2.\n",
      "  1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0.         0.00400401 0.00401204 0.00603319 0.01009593 0.0081136\n",
      " 0.01223245 0.0164272  0.01864333 0.02092069 0.02752823 0.03224143\n",
      " 0.03938858 0.0379264  0.03407237 0.04166817 0.04494571 0.07557267\n",
      " 0.04777097 0.05677801 0.05036714 0.04891548 0.05579162 0.06907161\n",
      " 0.04740963 0.05471466 0.05942579 0.06452172 0.07006555 0.06557965\n",
      " 0.08970113 0.09007151 0.11048174 0.17808367 0.20530831 0.08533289\n",
      " 0.12156978]\n",
      "[0.         0.00400401 0.00801604 0.01404923 0.02414516 0.03225876\n",
      " 0.04449122 0.06091841 0.07956174 0.10048243 0.12801066 0.16025209\n",
      " 0.19964067 0.23756707 0.27163945 0.31330762 0.35825333 0.433826\n",
      " 0.48159697 0.53837498 0.58874212 0.6376576  0.69344923 0.76252084\n",
      " 0.80993047 0.86464512 0.92407092 0.98859264 1.05865819 1.12423784\n",
      " 1.21393897 1.30401047 1.41449221 1.59257588 1.79788419 1.88321708\n",
      " 2.00478686]\n"
     ]
    }
   ],
   "source": [
    "# print(len(pgap_list))\n",
    "\n",
    "def get_pgap_by_plot_id(pgap_list, target_plot_id):\n",
    "    # Search for the target plot_id\n",
    "    for pgap_obj, plot_id in pgap_list:\n",
    "        if plot_id == target_plot_id:\n",
    "            return pgap_obj  # Return the matching object\n",
    "\n",
    "    # If not found\n",
    "    print(f\"Plot ID {target_plot_id} not found.\")\n",
    "    return None\n",
    "        \n",
    "pgap = get_pgap_by_plot_id(pgap_list, \"TEAK_044\")\n",
    "\n",
    "mask = (pgap.height > 0.1) & (~np.isnan(pgap.foliageDensity)) # exclude all data below height 0.1, as they are too large.  Also filter out NaN values\n",
    "pgap_ht = pgap.height[mask]\n",
    "pgap_fp = pgap.foliageDensity[mask]\n",
    "pgap_gap = pgap.gap[mask]\n",
    "\n",
    "# Calculate the height differences (dz)\n",
    "height_diffs = np.abs(np.diff(pgap_ht, prepend=pgap_ht[0]))\n",
    "\n",
    "pgap_acc_LAI = np.cumsum(pgap_fp * height_diffs)# Cumulative sum in reverse order\n",
    "\n",
    "print(pgap_ht)\n",
    "print(height_diffs)\n",
    "print(pgap_fp)\n",
    "print(pgap_acc_LAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_Li_dz(plot, trees, section_range, plot_area):\n",
    "    num_trees = len(plot.tree_individualID)\n",
    "    max_tree_height = max(tree.height for tree in trees if tree.individualID in plot.tree_individualID)\n",
    "\n",
    "    plot.tree_height_array = np.arange(0, max_tree_height + section_range, section_range)\n",
    "    plot.Li_dz_indiv = np.zeros((num_trees, len(plot.tree_height_array)))\n",
    "\n",
    "    LAI = plot.LAI\n",
    "\n",
    "    plot_crown_vols = []\n",
    "    \n",
    "    for index, tree_id in enumerate(plot.tree_individualID):\n",
    "        tree = next((t for t in trees if t.individualID == tree_id), None)\n",
    "        crown_volume = tree.crown_volume\n",
    "        plot_crown_vols.append(crown_volume)\n",
    "    \n",
    "    total_crown_volume = sum(plot_crown_vols)\n",
    "    \n",
    "    Fa = (LAI/total_crown_volume) * plot_area\n",
    "    print(f\"plot id: {plot.plotid}, num_trees: {num_trees}, max_tree_height: {max_tree_height}, LAI: {LAI}, total crown vol: {total_crown_volume}, Fa: {Fa}\")\n",
    "\n",
    "    for index, tree_id in enumerate(plot.tree_individualID):\n",
    "        # Find the tree with the matching individualID\n",
    "        tree = next((t for t in trees if t.individualID == tree_id), None)\n",
    "\n",
    "        tree_height = tree.height\n",
    "        crown_base_height = tree.baseCrownHeight\n",
    "        crown_radius = tree.horiz_crown_radius\n",
    "        crown_center_height = tree.crownCenterHeight\n",
    "        crown_vertical_radius = tree.vert_crown_radius\n",
    "\n",
    "        Li_dz = calculate_Li_dz_per_section(Fa, crown_base_height, crown_radius, crown_center_height, crown_vertical_radius, tree_height, plot.tree_height_array, section_range)\n",
    "\n",
    "        # # Print all values on one line\n",
    "        # print(f\"tree_id: {tree_id}, \"\n",
    "        #     f\"tree_height: {tree_height}, \"\n",
    "        #     f\"max tree height: {max_tree_height}, \"\n",
    "        #     f\"section range: {section_range}, \"\n",
    "        #     f\"num sections: {num_sections}, \"\n",
    "        #     f\"length of tree height array: {len(plot.tree_height_array)}, \"\n",
    "            # f\"crown_volume: {crown_volume}, \"\n",
    "            # f\"crown_base_height: {crown_base_height}, \"\n",
    "            # f\"crown_radius (horizontal): {crown_radius}, \"\n",
    "            # f\"crown_center_height: {crown_center_height}, \"\n",
    "            # f\"crown_vertical_radius: {crown_vertical_radius}, \"\n",
    "            # f\"LAI: {LAI}, \"\n",
    "            # f\"Li_dz shape: {Li_dz.shape}, \"\n",
    "            # f\"Li_dz_indiv[{index}] shape: {plot.Li_dz_indiv[index].shape}\")\n",
    "\n",
    "        # print(Li_dz)\n",
    "        plot.Li_dz_indiv[index, :len(Li_dz)] = Li_dz\n",
    "\n",
    "def calculate_Li_dz_per_section(Fa, crown_base_height, crown_radius, crown_center_height, crown_vertical_radius, tree_height, tree_height_array, section_range):\n",
    "    # Calculate the number of sections\n",
    "    num_sections = len(tree_height_array)\n",
    "    \n",
    "    # Initialize NumPy arrays to store leaf area, veg area, and volume per range height\n",
    "    Li_dz_per_range = np.zeros(num_sections, dtype=float)\n",
    "\n",
    "    # Calculate the leaf area, veg area, and volume for the rest of the ranges\n",
    "    for i in range(int(crown_base_height / section_range), int(tree_height / section_range) + 1):\n",
    "        Li_dz_per_range_single = Fa * math.pi * crown_radius**2 * abs(1- ((tree_height_array[i] - crown_center_height)/crown_vertical_radius)**2)\n",
    "        Li_dz_per_range[i] = Li_dz_per_range_single\n",
    "\n",
    "    return Li_dz_per_range\n",
    "\n",
    "def process_plots(teak_plot_objects, teak_tree_objects, plot_LAI_df, section_range, plot_area):\n",
    "    for plot in teak_plot_objects:\n",
    "        matching_row = plot_LAI_df[plot_LAI_df[\"namedLocation\"].str.contains(plot.plotid, na=False)]\n",
    "        # plot.LAI = matching_row[\"LAI_Average_exclude_negatives\"].values[0]\n",
    "        plot.LAI = matching_row[\"small_footprint_lidar_LAI\"].values[0]\n",
    "        # print(f\"plotid: {plot.plotid}, LAI: {plot.LAI}\")\n",
    "        calculate_Li_dz(plot, teak_tree_objects, section_range, plot_area)\n",
    "        plot.Li_dz_total = np.sum(plot.Li_dz_indiv, axis=0) / plot_area\n",
    "        plot.acc_LAI = np.cumsum(plot.Li_dz_total[::-1])[::-1] * section_range\n",
    "\n",
    "def calc_gap_and_wvfm(plot_objects):\n",
    "\n",
    "    for plot in plot_objects:\n",
    "        acc_LAI = plot.acc_LAI\n",
    "\n",
    "        plot.gap = np.exp(-acc_LAI / 2)\n",
    "\n",
    "        # Set the gap probability at the ground level based on the maximum acc_LAI\n",
    "        # max_acc_LAI = np.max(acc_LAI)  # Obtain the maximum value of acc_LAI\n",
    "        # plot.gap[0] = np.exp(- (max_acc_LAI * 1.1) / 2)\n",
    "\n",
    "        plot.waveform = np.zeros_like(plot.gap)\n",
    "\n",
    "        for i in range(len(plot.gap)):\n",
    "            if i == 0:  # First element\n",
    "                plot.waveform[i] = (plot.gap[i]) / section_range\n",
    "            elif i == len(plot.gap) - 1:  # Last element\n",
    "                plot.waveform[i] = (plot.gap[i] - plot.gap[i - 1]) / section_range\n",
    "            else:  # All other elements\n",
    "                plot.waveform[i] = (plot.gap[i + 1] - plot.gap[i - 1]) / (section_range * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot id: TEAK_001, num_trees: 11, max_tree_height: 23.9, LAI: 0.4095888252920266, total crown vol: 1269.505024945021, Fa: 0.1290546527170351\n",
      "plot id: TEAK_002, num_trees: 14, max_tree_height: 49.3, LAI: 3.228900908515289, total crown vol: 7398.22911220213, Fa: 0.17457696211055493\n",
      "plot id: TEAK_003, num_trees: 17, max_tree_height: 25.1, LAI: 0.9690166308972346, total crown vol: 1644.4197600712837, Fa: 0.2357102862483795\n",
      "plot id: TEAK_005, num_trees: 10, max_tree_height: 24.7, LAI: 1.4556183245217271, total crown vol: 2904.141446614005, Fa: 0.20048862650527727\n",
      "plot id: TEAK_006, num_trees: 12, max_tree_height: 27.4, LAI: 1.1292667198548043, total crown vol: 1768.8833778212038, Fa: 0.2553626166685476\n",
      "plot id: TEAK_007, num_trees: 12, max_tree_height: 22.5, LAI: 0.9605326423817256, total crown vol: 1512.2906649708498, Fa: 0.25406032441527776\n",
      "plot id: TEAK_010, num_trees: 4, max_tree_height: 36.7, LAI: 1.258467709632585, total crown vol: 1208.9250654873183, Fa: 0.4163922961181373\n",
      "plot id: TEAK_011, num_trees: 8, max_tree_height: 40.1, LAI: 0.9957415677850476, total crown vol: 1669.7799526081217, Fa: 0.2385324045194683\n",
      "plot id: TEAK_012, num_trees: 41, max_tree_height: 35.4, LAI: 1.778055162231582, total crown vol: 4880.234222769501, Fa: 0.14573523163587404\n",
      "plot id: TEAK_013, num_trees: 13, max_tree_height: 40.8, LAI: 2.517562081641862, total crown vol: 2871.557685369013, Fa: 0.3506893968342258\n",
      "plot id: TEAK_014, num_trees: 6, max_tree_height: 21.2, LAI: 0.8534204334438009, total crown vol: 937.8156725790107, Fa: 0.3640034852891203\n",
      "plot id: TEAK_015, num_trees: 45, max_tree_height: 33.9, LAI: 2.412622410515734, total crown vol: 3335.5290324021776, Fa: 0.289324108659095\n",
      "plot id: TEAK_016, num_trees: 6, max_tree_height: 22.5, LAI: 1.2132758753013255, total crown vol: 1426.1955190144859, Fa: 0.34028318253017936\n",
      "plot id: TEAK_017, num_trees: 12, max_tree_height: 23.6, LAI: 0.6894452208297825, total crown vol: 1497.4820262356227, Fa: 0.18416120093619104\n",
      "plot id: TEAK_018, num_trees: 6, max_tree_height: 40.0, LAI: 1.5881461982998115, total crown vol: 2838.9776940352053, Fa: 0.22376311045156347\n",
      "plot id: TEAK_019, num_trees: 23, max_tree_height: 38.1, LAI: 3.216874824201033, total crown vol: 12064.063040492782, Fa: 0.1066597484911562\n",
      "plot id: TEAK_020, num_trees: 14, max_tree_height: 30.8, LAI: 2.4806561810722427, total crown vol: 6227.731732318956, Fa: 0.1593296749247448\n",
      "plot id: TEAK_025, num_trees: 4, max_tree_height: 30.5, LAI: 0.5534187875646107, total crown vol: 1712.5525271472366, Fa: 0.12926173738717225\n",
      "plot id: TEAK_043, num_trees: 17, max_tree_height: 11.5, LAI: 0.7979722840209104, total crown vol: 398.6877950545072, Fa: 1.6011973156325279\n",
      "plot id: TEAK_044, num_trees: 77, max_tree_height: 33.3, LAI: 2.0047868618551337, total crown vol: 8950.48543467162, Fa: 0.17918910669038468\n",
      "plot id: TEAK_045, num_trees: 57, max_tree_height: 35.8, LAI: 2.1812882380378653, total crown vol: 6796.728054133254, Fa: 0.2567456835894879\n",
      "plot id: TEAK_046, num_trees: 101, max_tree_height: 33.4, LAI: 1.90501988404736, total crown vol: 4103.315427383602, Fa: 0.371410858903832\n",
      "plot id: TEAK_047, num_trees: 33, max_tree_height: 30.5, LAI: 1.639960103472493, total crown vol: 4872.326205741884, Fa: 0.26926934432917915\n"
     ]
    }
   ],
   "source": [
    "process_plots(teak_plot_objects_100, teak_tree_objects_100, plot_LAI_df, section_range, 400)\n",
    "process_plots(teak_plot_objects_400, teak_tree_objects_400, plot_LAI_df, section_range, 800)\n",
    "calc_gap_and_wvfm(teak_plot_objects_100)\n",
    "calc_gap_and_wvfm(teak_plot_objects_400)\n",
    "\n",
    "# print(len(teak_plot_objects_100))\n",
    "# print(len(teak_plot_objects_400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot ID: TEAK_001\n",
      "num trees: 11\n",
      "Plot ID: TEAK_002\n",
      "num trees: 14\n",
      "Plot ID: TEAK_003\n",
      "num trees: 17\n",
      "Plot ID: TEAK_005\n",
      "num trees: 10\n",
      "Plot ID: TEAK_006\n",
      "num trees: 12\n",
      "Plot ID: TEAK_007\n",
      "num trees: 12\n",
      "Plot ID: TEAK_010\n",
      "num trees: 4\n",
      "Plot ID: TEAK_011\n",
      "num trees: 8\n",
      "Plot ID: TEAK_012\n",
      "num trees: 41\n",
      "Plot ID: TEAK_013\n",
      "num trees: 13\n",
      "Plot ID: TEAK_014\n",
      "num trees: 6\n",
      "Plot ID: TEAK_015\n",
      "num trees: 45\n",
      "Plot ID: TEAK_016\n",
      "num trees: 6\n",
      "Plot ID: TEAK_017\n",
      "num trees: 12\n",
      "Plot ID: TEAK_018\n",
      "num trees: 6\n",
      "Plot ID: TEAK_019\n",
      "num trees: 23\n",
      "Plot ID: TEAK_020\n",
      "num trees: 14\n",
      "Plot ID: TEAK_025\n",
      "num trees: 4\n"
     ]
    }
   ],
   "source": [
    "def debug_teak_plots(teak_plot_objects):\n",
    "    for plot in teak_plot_objects:\n",
    "        print(f\"Plot ID: {plot.plotid}\")\n",
    "        for i in range(len(plot.tree_height_array)):\n",
    "            height = plot.tree_height_array[i]\n",
    "            # print(height)\n",
    "            Li_dz_total = plot.Li_dz_total[i] if i < len(plot.Li_dz_total) else None\n",
    "            acc_LAI = plot.acc_LAI[i] if i < len(plot.acc_LAI) else None\n",
    "            gap = plot.gap[i] if i < len(plot.gap) else None\n",
    "            waveform = plot.waveform[i] if i < len(plot.waveform) else None\n",
    "            \n",
    "            # print(f\"Height: {height}, Li_dz_total: {Li_dz_total}, acc_LAI: {acc_LAI}, gap: {gap}, waveform: {waveform}\")\n",
    "        print(f\"num trees: {len(plot.tree_individualID)}\")\n",
    "        # print(\"\\n\")  # Add a new line for better readability between plots\n",
    "\n",
    "debug_teak_plots(teak_plot_objects_100)\n",
    "# debug_teak_plots(teak_plot_objects_400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_teak_data(teak_plot_objects, pgap_list, orig_gort_path, nrows, ncols, suptitle, save_path, plot_type='fp', consistent_ylim=False):\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(20, 24))\n",
    "    axs = axs.flatten()  # Flatten the array of axes for easy indexing\n",
    "\n",
    "    orig_gort_list = find_gort_out_files(orig_gort_path)\n",
    "    \n",
    "    # Determine the data to plot based on plot_type\n",
    "    if plot_type == 'fp':\n",
    "        data_label = \"Foliage Density $m^2$/$m^3$\"\n",
    "        get_data = lambda plot: plot.Li_dz_total\n",
    "    elif plot_type == 'accLAI':\n",
    "        data_label = \"Accumulated LAI\"\n",
    "        get_data = lambda plot: plot.acc_LAI\n",
    "    elif plot_type == 'gap':\n",
    "        data_label = \"Gap\"\n",
    "        get_data = lambda plot: plot.gap\n",
    "    elif plot_type == 'waveform':\n",
    "        data_label = \"Waveform\"\n",
    "        get_data = lambda plot: plot.waveform\n",
    "    else:\n",
    "        raise ValueError(\"Invalid plot_type. Choose from 'fp', 'accLAI', 'gap', or 'waveform'.\")\n",
    "\n",
    "    # Set y-axis limits if consistent_ylim is True\n",
    "    if consistent_ylim:\n",
    "        all_heights = np.concatenate([plot.tree_height_array for plot in teak_plot_objects])\n",
    "        ymin, ymax = all_heights.min(), all_heights.max()\n",
    "\n",
    "    for i, plot in enumerate(teak_plot_objects):\n",
    "        matching_gort_file = next((item for item in orig_gort_list if item['name'] == plot.plotid), None)\n",
    "\n",
    "        if matching_gort_file:\n",
    "            # print(f'gort file found: {matching_gort_file}')\n",
    "            \n",
    "            # Call the read_gort_out_data function with the path of the matching file\n",
    "            ht, fp, efp, pgap, groups = read_gort_out_data(matching_gort_file['path'])\n",
    "\n",
    "            # fp should be modified depending on the number of groups            \n",
    "            if groups == 1:\n",
    "                fp = fp * 2\n",
    "            if groups == 2:\n",
    "                fp = fp\n",
    "            if groups == 3:\n",
    "                fp = (fp * 2)/3\n",
    "                \n",
    "            # Determine the data to plot based on plot_type\n",
    "            if plot_type == 'fp':\n",
    "                axs[i].plot(fp, ht, label='Original GORT Data fp/efp', color='r', linestyle='--')\n",
    "                axs[i].set_xlim(0, 0.22)\n",
    "            elif plot_type == 'accLAI':\n",
    "                accLAI = np.cumsum(fp[::-1])[::-1] * section_range\n",
    "                print(accLAI)\n",
    "                axs[i].plot(accLAI, ht, label='Original GORT Data accLAI', color='r', linestyle=':')\n",
    "                # axs[i].set_xlim(0, 4)\n",
    "            elif plot_type == 'gap':\n",
    "                axs[i].plot(pgap, ht, label='Original GORT Data pgap', color='r', linestyle='-.')\n",
    "                # axs[i].set_xlim(0, 1.1)\n",
    "            \n",
    "        height = plot.tree_height_array\n",
    "        axs[i].plot(get_data(plot), height, label='New GORT Data', color='b')\n",
    "\n",
    "        # Find matching pgap data based on plotid\n",
    "        pgap_data = next((pgap for pgap, plotid in pgap_list if plotid == plot.plotid), None)\n",
    "\n",
    "        if pgap_data:\n",
    "            # Extract foliageDensity, gap, and accLAI before the if/elif block\n",
    "            mask = (pgap_data.height > 0.1) & (~np.isnan(pgap_data.foliageDensity)) # exclude all data below height 0.1, as they are too large.  Also filter out NaN values\n",
    "            pgap_ht = pgap_data.height[mask]\n",
    "            pgap_fp = pgap_data.foliageDensity[mask]\n",
    "            pgap_gap = pgap_data.gap[mask]\n",
    "            \n",
    "            # Calculate the height differences (dz)\n",
    "            height_diffs = np.abs(np.diff(pgap_ht, prepend=pgap_ht[0]))\n",
    "\n",
    "            pgap_acc_LAI = np.cumsum(pgap_fp * height_diffs) # Cumulative sum multiplied by dz\n",
    "            \n",
    "            # Plot data based on plot_type\n",
    "            if plot_type == 'fp':\n",
    "                print(np.nanmax(pgap_fp))\n",
    "                axs[i].plot(pgap_fp, pgap_ht, label='Small Footprint fp', color='green')\n",
    "            elif plot_type == 'accLAI':\n",
    "                axs[i].plot(pgap_acc_LAI, pgap_ht, label='Small Footprint accLAI', color='green')\n",
    "            elif plot_type == 'gap':\n",
    "                axs[i].plot(pgap_gap, pgap_ht, label='Small footprint Gap', color='green')\n",
    "        \n",
    "        if consistent_ylim:\n",
    "            axs[i].set_ylim(ymin, ymax)\n",
    "            \n",
    "        axs[i].set_title(plot.plotid)\n",
    "        axs[i].set_xlabel(data_label)\n",
    "        axs[i].set_ylabel(\"Height (m)\")\n",
    "        axs[i].grid()\n",
    "        axs[i].legend()\n",
    "        axs[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    for j in range(i + 1, nrows * ncols):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    \n",
    "    # Create the full path\n",
    "    full_save_path = os.path.join(save_path, date_subfolder, plot_type)\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(full_save_path, exist_ok=True)\n",
    "    # Save the figure\n",
    "    fig.savefig(os.path.join(full_save_path, f\"{suptitle}.png\"), bbox_inches='tight')\n",
    "    print(f\"fig saved to: {full_save_path}/{suptitle}.png\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def find_gort_out_files(directory):\n",
    "    txt_files_list = []\n",
    "    \n",
    "    # Traverse through the directory using os.walk()\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file ends with .txt and matches the pattern\n",
    "            if file.endswith(\".out\"):\n",
    "                # Strip the file extension and the extra parts (.in.gwvfm.txt)\n",
    "                stripped_name = file.split(\".out\")[0]\n",
    "                \n",
    "                # Create a dictionary with stripped name and file path\n",
    "                file_dict = {\n",
    "                    'name': stripped_name,\n",
    "                    'path': os.path.join(root, file)\n",
    "                }\n",
    "                \n",
    "                # Append the dictionary to the list\n",
    "                txt_files_list.append(file_dict)\n",
    "\n",
    "    return txt_files_list\n",
    "\n",
    "def read_gort_out_data(gort_out_location):\n",
    "    height = []\n",
    "    fp = []\n",
    "    efp = []\n",
    "    pgap = []\n",
    "    \n",
    "    gort_in_location = gort_out_location.replace(\".out\", \".in\")\n",
    "    \n",
    "    with open(gort_in_location) as gort_in:\n",
    "        first_line = gort_in.readline().strip()\n",
    "    \n",
    "    groups = int(first_line)\n",
    "    \n",
    "    with open(gort_out_location) as idl:\n",
    "        for line in idl:\n",
    "            if 'gamma:' in line:\n",
    "                print('Found \"gamma:\" line')\n",
    "                break  # Stop reading once we find the \"gamma:\" line\n",
    "            \n",
    "        for line in idl:\n",
    "            parts = line.split()\n",
    "            \n",
    "            # Check if the line contains exactly 6 columns (assuming this is the data you need)\n",
    "            if len(parts) == 6:\n",
    "                # Start reading from this line\n",
    "                height.append(float(parts[0]))\n",
    "                fp.append(float(parts[1]))\n",
    "                efp.append(float(parts[2]))\n",
    "                pgap.append(float(parts[3]))\n",
    "    \n",
    "    return np.array(height), np.array(fp), np.array(efp), np.array(pgap), groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['axes.labelsize'] = 24  # Size for x and y axis labels\n",
    "plt.rcParams['axes.titlesize'] = 24\n",
    "plt.rcParams['figure.titlesize'] = 30\n",
    "\n",
    "# plot_teak_data(teak_plot_objects_100, pgap_list, orig_gort_path, 4, 5, \"100 m2 plots FP\", output_path, plot_type='fp', consistent_ylim=True)\n",
    "# plot_teak_data(teak_plot_objects_400, pgap_list, orig_gort_path, 2, 3, \"400 m2 plots FP\", output_path, plot_type='fp', consistent_ylim=True)\n",
    "\n",
    "combined_plot_objects = teak_plot_objects_100 + teak_plot_objects_400\n",
    "\n",
    "plot_teak_data(combined_plot_objects, pgap_list, orig_gort_path, 5, 5, \"Combined 100 and 400 m2 plots FP\", output_path, plot_type='fp', consistent_ylim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_teak_data(teak_plot_objects_100, pgap_list, orig_gort_path, 4, 5, \"100 m2 Acc LAI\", output_path, plot_type='accLAI', consistent_ylim=True)\n",
    "# plot_teak_data(teak_plot_objects_400, pgap_list, orig_gort_path, 2, 3, \"400 m2 Acc LAI\", output_path, plot_type='accLAI', consistent_ylim=True)\n",
    "\n",
    "\n",
    "plot_teak_data(combined_plot_objects, pgap_list, orig_gort_path, 5, 5, \"Combined 100 and 400 m2 plots Acc LAI\", output_path, plot_type='accLAI', consistent_ylim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_teak_data(teak_plot_objects_100, pgap_list, orig_gort_path, 4, 5, \"100 m2 plots Gap Prob\", output_path, plot_type='gap', consistent_ylim=True)\n",
    "# plot_teak_data(teak_plot_objects_400, pgap_list, orig_gort_path, 2, 3, \"400 m2 plots Gap Prob\", output_path, plot_type='gap', consistent_ylim=True)\n",
    "\n",
    "plot_teak_data(combined_plot_objects, pgap_list, orig_gort_path, 5, 5, \"Combined 100 and 400 m2 plots Gap\", output_path, plot_type='gap', consistent_ylim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_teak_data(teak_plot_objects_100, pgap_list, orig_gort_path, 4, 5, \"100 m2 plots Waveform\", output_path, plot_type='waveform', consistent_ylim=True)\n",
    "# plot_teak_data(teak_plot_objects_400, pgap_list, orig_gort_path, 2, 3, \"400 m2 plots Waveform\", output_path, plot_type='waveform', consistent_ylim=True)\n",
    "\n",
    "plot_teak_data(combined_plot_objects, pgap_list, orig_gort_path, 5, 5, \"Combined 100 and 400 m2 plots waveform\", output_path, plot_type='waveform', consistent_ylim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(TEAK_class_declarations)\n",
    "\n",
    "def gsmooth(values, width, peak_scale=1.0):\n",
    "    # Apply scaling factor to the highest peaks\n",
    "    max_value = np.max(values)\n",
    "    scaled_values = np.copy(values)\n",
    "    scaled_values[values >= max_value * 0.9] *= peak_scale\n",
    "    \n",
    "    # Calculate convolution parameters and perform convolution\n",
    "    N = len(scaled_values)\n",
    "    N2 = int(np.ceil(width * 8))\n",
    "    if N2 > N / 2:\n",
    "        N2 = N // 2\n",
    "    N2 = int(N2 / 2) * 2 + 1\n",
    "    g1 = np.exp(-np.arange(-N2//2, N2//2)**2 / (2.0 * width**2))\n",
    "    g1 = g1 / np.sum(g1)\n",
    "    \n",
    "    smoothed_values = convolve(scaled_values, g1, mode='constant', cval=0.0)\n",
    "    \n",
    "    return smoothed_values\n",
    "\n",
    "def convolute_and_apply_smoothing(plot_objects, peak_scale=0.95):\n",
    "    \n",
    "    width = int(0.6 / section_range) + 1\n",
    "\n",
    "    for plot in plot_objects:\n",
    "        n_ext = int(10.0 / section_range)\n",
    "        height_array = plot.tree_height_array\n",
    "        waveform = plot.waveform\n",
    "\n",
    "        new_height_array = np.zeros(len(height_array) + n_ext, dtype=np.float32)\n",
    "        gsmooth_array = np.zeros(len(waveform) + n_ext, dtype=np.float32)\n",
    "        gaussian_array = np.zeros(len(waveform) + n_ext, dtype=np.float32)\n",
    "\n",
    "        for height_level in range(len(waveform)):\n",
    "            new_height_array[height_level + n_ext] = height_array[height_level]\n",
    "            gsmooth_array[height_level + n_ext] = waveform[height_level]\n",
    "            gaussian_array[height_level + n_ext] = waveform[height_level]\n",
    "\n",
    "        new_height_array[:n_ext] = np.arange(n_ext) * section_range - 10\n",
    "\n",
    "        plot.extended_height_array = new_height_array\n",
    "        # Apply custom gsmooth function\n",
    "        plot.gsmooth_wvfm = gsmooth(gsmooth_array, width, peak_scale)\n",
    "        # Apply scipy's gaussian_filter function\n",
    "        plot.gaussian_wvfm = gaussian_filter(gaussian_array, sigma=width, mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolute_and_apply_smoothing(teak_plot_objects_100)\n",
    "convolute_and_apply_smoothing(teak_plot_objects_400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_teak_waveforms(teak_plot_objects, pgap_list, orig_gort_path, nrows, ncols, suptitle, save_path, consistent_ylim=False, consistent_xlim=False):\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(20, 20))\n",
    "    axs = axs.flatten()  # Flatten the array of axes for easy indexing\n",
    "\n",
    "    orig_gort_list = find_txt_files(orig_gort_path)\n",
    "    \n",
    "    # Set y-axis limits if consistent_ylim is True\n",
    "    if consistent_ylim:\n",
    "        all_heights = np.concatenate([plot.extended_height_array for plot in teak_plot_objects])\n",
    "        ymin, ymax = all_heights.min(), all_heights.max()\n",
    "\n",
    "    for i, plot in enumerate(teak_plot_objects):\n",
    "        # Check if plot.plotid exists in the orig_gort_list\n",
    "        matching_gort_file = next((item for item in orig_gort_list if item['name'] == plot.plotid), None)\n",
    "\n",
    "        if matching_gort_file:\n",
    "            # Call the read_idl_waveform_data function with the path of the matching file\n",
    "            idl_waveform_ght, idl_waveform = read_idl_waveform_data(matching_gort_file['path'])\n",
    "            \n",
    "            # print(f\"plotid: {plot.plotid}, file found: {matching_gort_file['path']}\")\n",
    "            # Plot the GORT waveform data\n",
    "            axs[i].plot(idl_waveform, idl_waveform_ght, label='Original GORT Data', color='y', linestyle='-.')\n",
    "            # for x, val in enumerate(idl_waveform):\n",
    "                # print(f\"height: {idl_waveform_ght[x]}, wvm_val: {val}\")\n",
    "        \n",
    "        # Plot the waveform (original, gsmooth, and gaussian) vs height\n",
    "        axs[i].plot(plot.waveform, plot.tree_height_array, label='Raw Waveform', color='b')\n",
    "        axs[i].plot(plot.gsmooth_wvfm, plot.extended_height_array, label='Custom Gsmooth Function', color='g', linestyle='--')\n",
    "        axs[i].plot(plot.gaussian_wvfm, plot.extended_height_array, label='SciPy gaussian_filter', color='r', linestyle=':')\n",
    "\n",
    "        # Find matching pgap data based on plotid\n",
    "        pgap_data = next((pgap for pgap, plotid in pgap_list if plotid == plot.plotid), None)\n",
    "\n",
    "        if pgap_data:\n",
    "            # Extract foliageDensity, gap, and accLAI before the if/elif block\n",
    "            mask = (pgap_data.height > 0.1) & (~np.isnan(pgap_data.foliageDensity)) # exclude all data below height 0.1, as they are too large.  Also filter out NaN values\n",
    "            pgap_ht = pgap_data.height[mask]\n",
    "            pgap_gap = pgap_data.gap[mask]\n",
    "\n",
    "            pgap_wvfm = calc_smallfootprint_waveform(pgap_gap, pgap_ht)\n",
    "            \n",
    "            pgap_smoothed_wvfm, pgap_ext_ht = smooth_pgap_waveform(pgap_wvfm, pgap_ht)\n",
    "            \n",
    "            # axs[i].plot(pgap_smoothed_wvfm, pgap_ext_ht, label='Small Footprint pseudo wvfm', color='brown', linestyle='-')\n",
    "            axs[i].plot(pgap_smoothed_wvfm, pgap_ext_ht, label='Small Footprint pseudo wvfm', color='brown', linestyle='-')\n",
    "\n",
    "        axs[i].set_title(plot.plotid)\n",
    "        axs[i].set_xlabel(\"Waveform Values\")\n",
    "        axs[i].set_ylabel(\"Height (m)\")\n",
    "        axs[i].grid()\n",
    "        axs[i].legend()\n",
    "        axs[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        if consistent_ylim:\n",
    "            axs[i].set_ylim(ymin, ymax)\n",
    "        \n",
    "        if consistent_xlim:\n",
    "            axs[i].set_xlim(0, 0.3)\n",
    "\n",
    "    # Turn off extra subplots if necessary\n",
    "    for j in range(i + 1, nrows * ncols):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "    # Create the full path for saving the plot\n",
    "    full_save_path = os.path.join(save_path, date_subfolder, \"combined_waveforms\")\n",
    "    os.makedirs(full_save_path, exist_ok=True)\n",
    "    fig.savefig(os.path.join(full_save_path, f\"{suptitle}.png\"), bbox_inches='tight')\n",
    "    print(f\"fig saved to: {full_save_path}/{suptitle}.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def calc_smallfootprint_waveform(gap_array, height_array):\n",
    "    # Calculate height differences (dz)\n",
    "    height_diffs = np.diff(height_array, prepend=height_array[0])\n",
    "    if len(height_diffs) > 0:\n",
    "        height_diffs[0] = height_diffs[1]\n",
    "    \n",
    "    # Initialize the waveform array with zeros\n",
    "    waveform_array = np.zeros_like(gap_array)\n",
    "\n",
    "    # Calculate the waveform based on the gap array\n",
    "    for i in range(len(gap_array)):\n",
    "        if i == 0:  # First element\n",
    "            waveform_array[i] = gap_array[i] / height_diffs[i]\n",
    "        elif i == len(gap_array) - 1:  # Last element\n",
    "            waveform_array[i] = (gap_array[i] - gap_array[i - 1]) / height_diffs[i]\n",
    "        else:  # All other elements\n",
    "            waveform_array[i] = (gap_array[i + 1] - gap_array[i - 1]) / (height_diffs[i] + height_diffs[i - 1]) \n",
    "\n",
    "    return waveform_array\n",
    "\n",
    "def find_txt_files(directory):\n",
    "    txt_files_list = []\n",
    "    \n",
    "    # Traverse through the directory using os.walk()\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file ends with .txt and matches the pattern\n",
    "            if file.endswith(\".txt\"):\n",
    "                # Strip the file extension and the extra parts (.in.gwvfm.txt)\n",
    "                stripped_name = file.split(\".in.gwvfm.txt\")[0]\n",
    "                \n",
    "                # Create a dictionary with stripped name and file path\n",
    "                file_dict = {\n",
    "                    'name': stripped_name,\n",
    "                    'path': os.path.join(root, file)\n",
    "                }\n",
    "                \n",
    "                # Append the dictionary to the list\n",
    "                txt_files_list.append(file_dict)\n",
    "\n",
    "    return txt_files_list\n",
    "\n",
    "def read_idl_waveform_data(idl_wvfm_location):\n",
    "    gwvform_ght = []\n",
    "    gwvform = []\n",
    "    \n",
    "    with open(idl_wvfm_location) as idl:\n",
    "        for i, line in enumerate(idl):\n",
    "            if i < 4:\n",
    "                continue  # Skip the first four lines\n",
    "            parts = line.split()\n",
    "            \n",
    "            gwvform_ght.append(float(parts[0]))\n",
    "            gwvform.append(float(parts[1]))\n",
    "    \n",
    "    return np.array(gwvform_ght), np.array(gwvform)\n",
    "\n",
    "def smooth_pgap_waveform(waveform, height_array, peak_scale=0.95):\n",
    "    # Calculate section_range (dz) from the height array\n",
    "    section_range = np.abs(np.diff(height_array, prepend=height_array[0]))\n",
    "    if len(section_range) > 0:\n",
    "        section_range[0] = section_range[1]\n",
    "    \n",
    "    # Calculate the width based on the section range\n",
    "    width = int(0.6 / section_range[0]) + 1  # Assuming uniform section range\n",
    "\n",
    "    # Extend the waveform array\n",
    "    n_ext = int(10.0 / section_range[0])\n",
    "    extended_waveform = np.zeros(len(waveform) + n_ext, dtype=np.float32)\n",
    "\n",
    "    # Fill the extended waveform\n",
    "    extended_waveform[n_ext:n_ext + len(waveform)] = waveform\n",
    "    extended_waveform[:n_ext] = np.arange(n_ext) * section_range[0] - 10  # Example filling for extension\n",
    "\n",
    "    # Extend the height array\n",
    "    extended_height_array = np.zeros(len(height_array) + n_ext, dtype=np.float32)\n",
    "    extended_height_array[n_ext:n_ext + len(height_array)] = height_array\n",
    "    extended_height_array[:n_ext] = np.arange(n_ext) * section_range[0] - 10  # Example filling for extension\n",
    "\n",
    "    # Apply Gaussian filter to the extended waveform\n",
    "    smoothed_waveform = gaussian_filter(extended_waveform, sigma=width, mode='nearest')\n",
    "    \n",
    "    return smoothed_waveform, extended_height_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_teak_waveforms(teak_plot_objects_100, pgap_list, orig_gort_path, 4, 5, \"100 m2 Combined Waveforms\", output_path, consistent_ylim=True, consistent_xlim=True)\n",
    "# plot_teak_waveforms(teak_plot_objects_400, pgap_list, orig_gort_path, 2, 3, \"400 m2 Combined Waveforms\", output_path, consistent_ylim=True, consistent_xlim=True)\n",
    "\n",
    "plot_teak_waveforms(combined_plot_objects, pgap_list, orig_gort_path, 5, 5, \"100 and 400 m2 Combined Waveforms\", output_path, consistent_ylim=True, consistent_xlim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_teak_waveforms(teak_plot_objects, pgap_list, orig_gort_path, nrows, ncols, suptitle, save_path, consistent_ylim=False, consistent_xlim=False):\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(20, 25))\n",
    "    axs = axs.flatten()  # Flatten the array of axes for easy indexing\n",
    "\n",
    "    orig_gort_list = find_gort_out_files(orig_gort_path)\n",
    "\n",
    "    # Initialize empty lists to collect handles and labels for the global legend\n",
    "    handles, labels = [], []\n",
    "    \n",
    "    # Create empty list to collect all heights (to calculate ymax later)\n",
    "    all_heights = []\n",
    "    all_pgap_heights = []\n",
    "\n",
    "    for i, plot in enumerate(teak_plot_objects):\n",
    "        # Check if plot.plotid exists in the orig_gort_list\n",
    "        matching_gort_file = next((item for item in orig_gort_list if item['name'] == plot.plotid), None)\n",
    "\n",
    "        if matching_gort_file:\n",
    "            # Call the read_idl_waveform_data function with the path of the matching file\n",
    "            height_array, smoothed_waveform = process_out_file(matching_gort_file['path'])\n",
    "            \n",
    "            # print(f\"plotid: {plot.plotid}, file found: {matching_gort_file['path']}\")\n",
    "            # Plot the GORT waveform data\n",
    "            line, = axs[i].plot(smoothed_waveform, height_array, label='Original GORT Data', color='r', linestyle='-.')\n",
    "            if 'Original GORT Data' not in labels:\n",
    "                handles.append(line)\n",
    "                labels.append('Original GORT Data')\n",
    "            # for x, val in enumerate(idl_waveform):\n",
    "                # print(f\"height: {idl_waveform_ght[x]}, wvm_val: {val}\")\n",
    "        \n",
    "        # Plot the waveform (original, gsmooth, and gaussian) vs height\n",
    "        line, = axs[i].plot(plot.gsmooth_wvfm, plot.extended_height_array, label='New GORT Data', color='b', linestyle='--')\n",
    "        if 'New GORT Data' not in labels:\n",
    "            handles.append(line)\n",
    "            labels.append('New GORT Data')\n",
    "        # Append the heights to the all_heights list\n",
    "        all_heights.extend(plot.extended_height_array)\n",
    "\n",
    "        # Find matching pgap data based on plotid\n",
    "        pgap_data = next((pgap for pgap, plotid in pgap_list if plotid == plot.plotid), None)\n",
    "\n",
    "        if pgap_data:\n",
    "            # Extract foliageDensity, gap, and accLAI before the if/elif block\n",
    "            mask = (pgap_data.height > 0.1) & (~np.isnan(pgap_data.foliageDensity)) # exclude all data below height 0.1, as they are too large.  Also filter out NaN values\n",
    "            pgap_ht = pgap_data.height[mask]\n",
    "            pgap_gap = pgap_data.gap[mask]\n",
    "\n",
    "            pgap_wvfm = calc_smallfootprint_waveform(pgap_gap, pgap_ht)\n",
    "            \n",
    "            pgap_smoothed_wvfm, pgap_ext_ht = smooth_pgap_waveform(pgap_wvfm, pgap_ht)\n",
    "            \n",
    "            # Append the pgap_ext_ht to the all_pgap_heights list\n",
    "            all_pgap_heights.extend(pgap_ext_ht)\n",
    "            \n",
    "            # axs[i].plot(pgap_smoothed_wvfm, pgap_ext_ht, label='Small Footprint pseudo wvfm', color='brown', linestyle='-')\n",
    "            line, = axs[i].plot(pgap_smoothed_wvfm, pgap_ext_ht, label='Small Footprint pseudo wvfm', color='green', linestyle='-')\n",
    "            if 'Small Footprint pseudo wvfm' not in labels:\n",
    "                handles.append(line)\n",
    "                labels.append('Small Footprint pseudo wvfm')\n",
    "\n",
    "        axs[i].set_title(plot.plotid)\n",
    "        axs[i].set_xlabel(\"Waveform Values\")\n",
    "        axs[i].set_ylabel(\"Height (m)\")\n",
    "        axs[i].grid()\n",
    "        axs[i].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        if consistent_xlim:\n",
    "            axs[i].set_xlim(0, 0.05)\n",
    "\n",
    "    # After all subplots, calculate the global ymin and ymax\n",
    "    if consistent_ylim:\n",
    "        # Combine all heights (from both the plot and pgap data) for the global ymin, ymax calculation\n",
    "        combined_heights = np.concatenate([all_heights, all_pgap_heights])\n",
    "        ymin, ymax = combined_heights.min(), combined_heights.max()\n",
    "\n",
    "        # Apply consistent y-limits across all subplots\n",
    "        for ax in axs:\n",
    "            ax.set_ylim(ymin, ymax)\n",
    "\n",
    "    # Turn off extra subplots if necessary\n",
    "    for j in range(i + 1, nrows * ncols):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "\n",
    "    # Create the full path for saving the plot\n",
    "    full_save_path = os.path.join(save_path, date_subfolder, \"combined_waveforms\")\n",
    "    os.makedirs(full_save_path, exist_ok=True)\n",
    "    fig.savefig(os.path.join(full_save_path, f\"{suptitle}.png\"), bbox_inches='tight')\n",
    "    print(f\"fig saved to: {full_save_path}/{suptitle}.png\")\n",
    "\n",
    "    # Add a legend inside the plot area (bottom right)\n",
    "    plt.legend(handles=handles, labels=labels, loc='lower right', fontsize=14)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def process_out_file(out_file):\n",
    "    \n",
    "    with open(out_file) as gort_out:\n",
    "        \n",
    "        gn_level, dz = map(float, gort_out.readline().split())\n",
    "        n_ext = int(10.0 / dz)\n",
    "        n_tot = int(gn_level + n_ext)\n",
    "\n",
    "        height_array = np.zeros(n_tot, dtype=np.float32)\n",
    "        waveform_array = np.zeros(n_tot, dtype=np.float32)\n",
    "\n",
    "        height_array[:n_ext] = np.arange(n_ext) * dz - 10  # extend height to below ground 10m deep\n",
    "        \n",
    "        for line in gort_out:\n",
    "            if 'gamma:' in line:\n",
    "                # print('Found \"gamma:\" line')\n",
    "                break  # Stop reading once we find the \"gamma:\" line\n",
    "        \n",
    "        print(out_file, gn_level, dz, n_tot)\n",
    "            \n",
    "        for line in gort_out:\n",
    "            parts = line.split()\n",
    "            parts = [float(part) for part in parts]\n",
    "            \n",
    "            # Check if the line contains exactly 6 columns (assuming this is the data you need)\n",
    "            if len(parts) == 6:\n",
    "                \n",
    "                # Start reading from this line\n",
    "                for ilevel in range(int(gn_level)):\n",
    "                    height_array[ilevel + n_ext] = parts[0]\n",
    "                    waveform_array[ilevel + n_ext] = parts[5]\n",
    "                    print(f\"line: {line}, parts[0]: {parts[0]}, parts[5]: {parts[5]}\")\n",
    "\n",
    "        # checks only 1 file for debug\n",
    "        if 'TEAK_001' in out_file:\n",
    "            print(f\"height_array: {height_array}\")\n",
    "            print(f\"waveform_array: {waveform_array}\")\n",
    "\n",
    "        width = int(0.6 / dz) + 1\n",
    "        smoothed_waveform = gaussian_filter(waveform_array, sigma=width, mode='nearest')\n",
    "        print(len(height_array), len(smoothed_waveform))\n",
    "        # print(height_array, smoothed_waveform)\n",
    "    \n",
    "    return height_array, smoothed_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_teak_waveforms(combined_plot_objects, pgap_list, orig_gort_path, 5, 5, \"100 and 400 m2 Combined Waveforms\", output_path, consistent_ylim=True, consistent_xlim=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
